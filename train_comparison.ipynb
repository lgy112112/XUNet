{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该如何加载这些数据呢？首先我们肯定能确认：图像和它对应的掩码肯定是成对出现的。\n",
    "\n",
    "按照我的习惯，我会事先将所有图像和掩码的路径都写在一个metadata.csv中，这样可以方便地读取。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以展开下方的cell运行，得到metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.csv 已保存到: lgg-mri-segmentation/kaggle_3m/metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "# 指定根文件夹路径\n",
    "root_folder = 'lgg-mri-segmentation/kaggle_3m'\n",
    "\n",
    "# 列表用于存储image和mask路径\n",
    "data = {'image_path': [], 'mask_path': []}\n",
    "\n",
    "# 遍历根文件夹下的所有子文件夹\n",
    "for sub_folder in os.listdir(root_folder):\n",
    "    sub_folder_path = os.path.join(root_folder, sub_folder)\n",
    "\n",
    "    # 检查是否为文件夹\n",
    "    if os.path.isdir(sub_folder_path):\n",
    "        # 遍历子文件夹中的所有文件\n",
    "        for file_name in os.listdir(sub_folder_path):\n",
    "            if file_name.endswith('.tif') and '_mask' not in file_name:\n",
    "                # 获取切片路径\n",
    "                slice_path = os.path.join(sub_folder_path, file_name)\n",
    "\n",
    "                # 获取对应的掩膜文件路径\n",
    "                base_name = file_name.replace('.tif', '')\n",
    "                mask_file_name = base_name + '_mask.tif'\n",
    "                mask_path = os.path.join(sub_folder_path, mask_file_name)\n",
    "                \n",
    "                # 仅当掩膜文件存在时，记录图像和掩膜路径\n",
    "                if os.path.exists(mask_path):\n",
    "                    data['image_path'].append(slice_path)\n",
    "                    data['mask_path'].append(mask_path)\n",
    "\n",
    "# 创建DataFrame并写入CSV文件\n",
    "df = pd.DataFrame(data)\n",
    "csv_output_path = os.path.join(root_folder, 'metadata.csv')\n",
    "df.to_csv(csv_output_path, index=False)\n",
    "\n",
    "print(f\"metadata.csv 已保存到: {csv_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms\n",
    "\n",
    "# 自定义 PyTorch Dataset\n",
    "class BrainLesionDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data.iloc[idx]['image_path']\n",
    "        mask_path = self.data.iloc[idx]['mask_path']\n",
    "        \n",
    "        # 打开图像和掩膜\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')  # 掩膜为灰度图像\n",
    "\n",
    "        # 如果有transform，应用到图像和掩膜\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask.long() # 强调一下要整数不要浮点数\n",
    "\n",
    "# PyTorch Lightning DataModule\n",
    "class BrainLesionDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, csv_file, batch_size=16, num_workers=4, transform=None, split_ratio=(0.6, 0.2, 0.2), seed=42):\n",
    "        super().__init__()\n",
    "        self.csv_file = csv_file\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transform\n",
    "        self.split_ratio = split_ratio  # 训练、验证和测试集的划分比例\n",
    "        self.seed = seed\n",
    "        self.generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "    # 准备数据集\n",
    "    def setup(self, stage=None):\n",
    "        # 创建完整的数据集\n",
    "        full_dataset = BrainLesionDataset(self.csv_file, transform=self.transform)\n",
    "\n",
    "        # 计算每个数据集的大小\n",
    "        dataset_size = len(full_dataset)\n",
    "        train_size = int(self.split_ratio[0] * dataset_size)\n",
    "        val_size = int(self.split_ratio[1] * dataset_size)\n",
    "        test_size = dataset_size - train_size - val_size\n",
    "\n",
    "        # 使用 random_split 进行数据集划分\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(full_dataset, [train_size, val_size, test_size], generator=self.generator)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False)\n",
    "\n",
    "# 示例的 transform，可以根据任务要求更改\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((256, 256)), # 因为已经是256规格，所以在这里我不进行resize，实际上你可以进行128的resize，但请注意resize方法，掩码只适合使用最近邻插值的resize方法\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照Pytorch Lightning的使用规范，我们可以实例化出train_loader/val_loader/test_loader，然后可以检查里面的东西。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([16, 1, 256, 256]), Masks shape: torch.Size([16, 1, 256, 256])\n",
      "Image min&Max: (tensor(0.), tensor(0.8902)), Masks unique: [0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "num_workers = os.cpu_count()\n",
    "csv_file = 'lgg-mri-segmentation/kaggle_3m/metadata.csv'\n",
    "# 定义 DataModule，使用自动获得的 num_workers\n",
    "data_module = BrainLesionDataModule(csv_file, batch_size=16, num_workers=num_workers, transform=transform)\n",
    "\n",
    "# 检查 DataModule 是否正常工作\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "\n",
    "# 打印第一个 batch 的形状\n",
    "for batch in train_loader:\n",
    "    images, masks = batch\n",
    "    print(f\"Images shape: {images.shape}, Masks shape: {masks.shape}\")\n",
    "    print(f\"Image min&Max: {images.min(), images.max()}, Masks unique: {np.unique(masks)}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlgy112112\u001b[0m (\u001b[33msouthern\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241116_124911-ntrtowgt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/southern/CrossUNet/runs/ntrtowgt' target=\"_blank\">CrossUNet</a></strong> to <a href='https://wandb.ai/southern/CrossUNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/southern/CrossUNet' target=\"_blank\">https://wandb.ai/southern/CrossUNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/southern/CrossUNet/runs/ntrtowgt' target=\"_blank\">https://wandb.ai/southern/CrossUNet/runs/ntrtowgt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from monai.losses import DiceCELoss\n",
    "# !pip install -U torchmetrics # fuck torchmetrics终于加入了分割用的Dice\n",
    "# from torchmetrics.segmentation import GeneralizedDiceScore # https://lightning.ai/docs/torchmetrics/stable/segmentation/generalized_dice.html\n",
    "from monai.networks.nets import CrossBasicUNet # 在此，我们将BasicUNet导入进来\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import ToPILImage\n",
    "to_pil = ToPILImage()\n",
    "\n",
    "class CrossBasicUNetLightning(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = CrossBasicUNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            features=(64,64,128,256,512,64),\n",
    "            dropout=0.25,\n",
    "        )\n",
    "        self.loss = DiceCELoss()\n",
    "        self.dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.model(x))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.loss(outputs, masks)\n",
    "        \n",
    "        # 对模型输出进行阈值化处理\n",
    "        thresholded_outputs = (outputs > 0.5).float()\n",
    "        \n",
    "        # 计算 Dice 系数\n",
    "        self.dice_metric(y_pred=thresholded_outputs, y=masks)\n",
    "        dice_score = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"train_dice\", dice_score, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.loss(outputs, masks)\n",
    "        \n",
    "        # 对模型输出进行阈值化处理\n",
    "        thresholded_outputs = (outputs > 0.5).float()\n",
    "        \n",
    "        # 计算 Dice 系数\n",
    "        self.dice_metric(y_pred=thresholded_outputs, y=masks)\n",
    "        dice_score = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        \n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"val_dice\", dice_score, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        \n",
    "        return loss  # 如果需要返回损失\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.loss(outputs, masks)\n",
    "        \n",
    "        # 对模型输出进行阈值化处理\n",
    "        thresholded_outputs = (outputs > 0.5).float()\n",
    "        \n",
    "        # 计算 Dice 系数\n",
    "        self.dice_metric(y_pred=thresholded_outputs, y=masks)\n",
    "        dice_score = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        \n",
    "        self.log(\"test_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"test_dice\", dice_score, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        \n",
    "        return loss  # 如果需要返回损失\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        os.makedirs(\"predictions\", exist_ok=True)\n",
    "        for i in range(images.size(0)):\n",
    "            image = to_pil(images[i])\n",
    "            mask = to_pil(masks[i].float())\n",
    "            output = to_pil(outputs[i].float())\n",
    "            combined_image = Image.new(\"RGB\", (image.width * 3, image.height))\n",
    "            combined_image.paste(image, (0, 0))       # 左边是原图\n",
    "            combined_image.paste(mask, (image.width, 0)) # 中间是真掩码\n",
    "            combined_image.paste(output, (image.width * 2, 0)) # 右边是预测掩码\n",
    "            combined_image.save(f\"predictions/prediction_{batch_idx}_{i}.png\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "import os\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# 初始化 WandbLogger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"CrossUNet\",  # 替换为你的 Wandb 项目名\n",
    "    name=\"CrossUNet\",\n",
    "    log_model=True,           # 让 Wandb 自动跟踪模型文件\n",
    ")\n",
    "\n",
    "# 获取 Wandb 日志目录\n",
    "checkpoint_dir = wandb_logger.experiment.dir  # Wandb 会自动生成日志文件夹\n",
    "\n",
    "# 定义检查点回调，将模型保存在 Wandb 日志目录中\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,                       # 使用 Wandb 的日志目录\n",
    "    filename=\"UNet-{epoch:02d}-{val_dice:.4f}\",   # 模型文件名格式化\n",
    "    monitor=\"val_dice\",                           # 监控的指标\n",
    "    mode=\"max\",                                   # 最大化监控指标\n",
    "    save_top_k=1,                                 # 仅保存最佳模型\n",
    "    save_last=True                                # 保存最后一个模型\n",
    ")\n",
    "\n",
    "# 定义 Trainer，添加自定义的回调\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,  # 你可以调整\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # overfit_batches=10,  # 可选调试\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model = CrossBasicUNetLightning()  # 替换为你的模型定义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, \n",
    "            data_module, \n",
    "            )\n",
    "trainer.test(model, data_module)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241116_133207-bqhjfydr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/southern/CrossUNet/runs/bqhjfydr' target=\"_blank\">BasicUNet</a></strong> to <a href='https://wandb.ai/southern/CrossUNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/southern/CrossUNet' target=\"_blank\">https://wandb.ai/southern/CrossUNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/southern/CrossUNet/runs/bqhjfydr' target=\"_blank\">https://wandb.ai/southern/CrossUNet/runs/bqhjfydr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (64, 64, 128, 256, 512, 64).\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from monai.losses import DiceCELoss\n",
    "# !pip install -U torchmetrics # fuck torchmetrics终于加入了分割用的Dice\n",
    "# from torchmetrics.segmentation import GeneralizedDiceScore # https://lightning.ai/docs/torchmetrics/stable/segmentation/generalized_dice.html\n",
    "from monai.networks.nets import CrossBasicUNet, BasicUNet # 在此，我们将BasicUNet导入进来\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import ToPILImage\n",
    "to_pil = ToPILImage()\n",
    "\n",
    "class BasicUNetLightning(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = BasicUNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            features=(64,64,128,256,512,64),\n",
    "            dropout=0.25,\n",
    "        )\n",
    "        self.loss = DiceCELoss()\n",
    "        self.dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.model(x))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.loss(outputs, masks)\n",
    "        \n",
    "        # 对模型输出进行阈值化处理\n",
    "        thresholded_outputs = (outputs > 0.5).float()\n",
    "        \n",
    "        # 计算 Dice 系数\n",
    "        self.dice_metric(y_pred=thresholded_outputs, y=masks)\n",
    "        dice_score = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"train_dice\", dice_score, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.loss(outputs, masks)\n",
    "        \n",
    "        # 对模型输出进行阈值化处理\n",
    "        thresholded_outputs = (outputs > 0.5).float()\n",
    "        \n",
    "        # 计算 Dice 系数\n",
    "        self.dice_metric(y_pred=thresholded_outputs, y=masks)\n",
    "        dice_score = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        \n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"val_dice\", dice_score, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        \n",
    "        return loss  # 如果需要返回损失\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.loss(outputs, masks)\n",
    "        \n",
    "        # 对模型输出进行阈值化处理\n",
    "        thresholded_outputs = (outputs > 0.5).float()\n",
    "        \n",
    "        # 计算 Dice 系数\n",
    "        self.dice_metric(y_pred=thresholded_outputs, y=masks)\n",
    "        dice_score = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        \n",
    "        self.log(\"test_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"test_dice\", dice_score, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        \n",
    "        return loss  # 如果需要返回损失\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        os.makedirs(\"predictions\", exist_ok=True)\n",
    "        for i in range(images.size(0)):\n",
    "            image = to_pil(images[i])\n",
    "            mask = to_pil(masks[i].float())\n",
    "            output = to_pil(outputs[i].float())\n",
    "            combined_image = Image.new(\"RGB\", (image.width * 3, image.height))\n",
    "            combined_image.paste(image, (0, 0))       # 左边是原图\n",
    "            combined_image.paste(mask, (image.width, 0)) # 中间是真掩码\n",
    "            combined_image.paste(output, (image.width * 2, 0)) # 右边是预测掩码\n",
    "            combined_image.save(f\"predictions/prediction_{batch_idx}_{i}.png\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "import os\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# 初始化 WandbLogger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"CrossUNet\",  # 替换为你的 Wandb 项目名\n",
    "    name=\"BasicUNet\",\n",
    "    log_model=True,           # 让 Wandb 自动跟踪模型文件\n",
    ")\n",
    "\n",
    "# 获取 Wandb 日志目录\n",
    "checkpoint_dir = wandb_logger.experiment.dir  # Wandb 会自动生成日志文件夹\n",
    "\n",
    "# 定义检查点回调，将模型保存在 Wandb 日志目录中\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,                       # 使用 Wandb 的日志目录\n",
    "    filename=\"UNet-{epoch:02d}-{val_dice:.4f}\",   # 模型文件名格式化\n",
    "    monitor=\"val_dice\",                           # 监控的指标\n",
    "    mode=\"max\",                                   # 最大化监控指标\n",
    "    save_top_k=1,                                 # 仅保存最佳模型\n",
    "    save_last=True                                # 保存最后一个模型\n",
    ")\n",
    "\n",
    "# 定义 Trainer，添加自定义的回调\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,  # 你可以调整\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # overfit_batches=10,  # 可选调试\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model = BasicUNetLightning() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, \n",
    "            data_module, \n",
    "            )\n",
    "trainer.test(model, data_module)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
